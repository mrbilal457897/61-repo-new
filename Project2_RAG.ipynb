{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPchNgLjD5z52WlMHiNEVz0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrbilal457897/61-repo-new/blob/main/Project2_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CURxU0-nVJNr"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
        "api_key = os.environ[\"GOOGLE_API_KEY\"]\n",
        "\n",
        "genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))"
      ],
      "metadata": {
        "id": "mn0IYNOjVUbb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(genai.list_models())"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "y5xRIyzZVrEh",
        "outputId": "883cd406-a964-4c3e-86bb-22df5f609392"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Model(name='models/chat-bison-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='PaLM 2 Chat (Legacy)',\n",
              "       description='A legacy text-only model optimized for chat conversations',\n",
              "       input_token_limit=4096,\n",
              "       output_token_limit=1024,\n",
              "       supported_generation_methods=['generateMessage', 'countMessageTokens'],\n",
              "       temperature=0.25,\n",
              "       max_temperature=None,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/text-bison-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='PaLM 2 (Legacy)',\n",
              "       description='A legacy model that understands text and generates text as an output',\n",
              "       input_token_limit=8196,\n",
              "       output_token_limit=1024,\n",
              "       supported_generation_methods=['generateText', 'countTextTokens', 'createTunedTextModel'],\n",
              "       temperature=0.7,\n",
              "       max_temperature=None,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/embedding-gecko-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Embedding Gecko',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=1024,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedText', 'countTextTokens'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-1.0-pro-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro Latest',\n",
              "       description=('The original Gemini 1.0 Pro model. This model will be discontinued on '\n",
              "                    'February 15th, 2025. Move to a newer Gemini version.'),\n",
              "       input_token_limit=30720,\n",
              "       output_token_limit=2048,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.9,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-1.0-pro',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro',\n",
              "       description='The best model for scaling across a wide range of tasks',\n",
              "       input_token_limit=30720,\n",
              "       output_token_limit=2048,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.9,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-pro',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro',\n",
              "       description='The best model for scaling across a wide range of tasks',\n",
              "       input_token_limit=30720,\n",
              "       output_token_limit=2048,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.9,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-1.0-pro-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro 001 (Tuning)',\n",
              "       description=('The original Gemini 1.0 Pro model version that supports tuning. Gemini 1.0 '\n",
              "                    'Pro will be discontinued on February 15th, 2025. Move to a newer Gemini '\n",
              "                    'version.'),\n",
              "       input_token_limit=30720,\n",
              "       output_token_limit=2048,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n",
              "       temperature=0.9,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-1.0-pro-vision-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro Vision',\n",
              "       description=('The original Gemini 1.0 Pro Vision model version which was optimized for '\n",
              "                    'image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. '\n",
              "                    'Move to a newer Gemini version.'),\n",
              "       input_token_limit=12288,\n",
              "       output_token_limit=4096,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.4,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=32),\n",
              " Model(name='models/gemini-pro-vision',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro Vision',\n",
              "       description=('The original Gemini 1.0 Pro Vision model version which was optimized for '\n",
              "                    'image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. '\n",
              "                    'Move to a newer Gemini version.'),\n",
              "       input_token_limit=12288,\n",
              "       output_token_limit=4096,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.4,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=32),\n",
              " Model(name='models/gemini-1.5-pro-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Pro Latest',\n",
              "       description=('Alias that points to the most recent production (non-experimental) release '\n",
              "                    'of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 '\n",
              "                    'million tokens.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-pro-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Pro 001',\n",
              "       description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n",
              "                    'supports up to 2 million tokens, released in May of 2024.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-pro-002',\n",
              "       base_model_id='',\n",
              "       version='002',\n",
              "       display_name='Gemini 1.5 Pro 002',\n",
              "       description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n",
              "                    'supports up to 2 million tokens, released in September of 2024.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-pro',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Pro',\n",
              "       description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n",
              "                    'supports up to 2 million tokens, released in May of 2024.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-pro-exp-0801',\n",
              "       base_model_id='',\n",
              "       version='exp-0801',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (December 6th, 2024) of Gemini.',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-pro-exp-0827',\n",
              "       base_model_id='',\n",
              "       version='exp-1206',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (December 6th, 2024) of Gemini.',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-flash-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash Latest',\n",
              "       description=('Alias that points to the most recent production (non-experimental) release '\n",
              "                    'of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling '\n",
              "                    'across diverse tasks.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash 001',\n",
              "       description=('Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model '\n",
              "                    'for scaling across diverse tasks, released in May of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-flash-001-tuning',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash 001 Tuning',\n",
              "       description=('Version of Gemini 1.5 Flash that supports tuning, our fast and versatile '\n",
              "                    'multimodal model for scaling across diverse tasks, released in May of 2024.'),\n",
              "       input_token_limit=16384,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-flash',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash',\n",
              "       description=('Alias that points to the most recent stable version of Gemini 1.5 Flash, our '\n",
              "                    'fast and versatile multimodal model for scaling across diverse tasks.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-exp-0827',\n",
              "       base_model_id='',\n",
              "       version='exp-1206',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (December 6th, 2024) of Gemini.',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-flash-002',\n",
              "       base_model_id='',\n",
              "       version='002',\n",
              "       display_name='Gemini 1.5 Flash 002',\n",
              "       description=('Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model '\n",
              "                    'for scaling across diverse tasks, released in September of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash-8B',\n",
              "       description=('Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective '\n",
              "                    'Flash model, released in October of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash-8B 001',\n",
              "       description=('Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective '\n",
              "                    'Flash model, released in October of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash-8B Latest',\n",
              "       description=('Alias that points to the most recent production (non-experimental) release '\n",
              "                    'of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, '\n",
              "                    'released in October of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-exp-0827',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash 8B Experimental 0827',\n",
              "       description=('Experimental release (August 27th, 2024) of Gemini 1.5 Flash-8B, our '\n",
              "                    'smallest and most cost effective Flash model. Replaced by '\n",
              "                    'Gemini-1.5-flash-8b-001 (stable).'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-exp-0924',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash 8B Experimental 0924',\n",
              "       description=('Experimental release (September 24th, 2024) of Gemini 1.5 Flash-8B, our '\n",
              "                    'smallest and most cost effective Flash model. Replaced by '\n",
              "                    'Gemini-1.5-flash-8b-001 (stable).'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-flash-exp',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash Experimental',\n",
              "       description='Gemini 2.0 Flash Experimental',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'bidiGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-exp-1206',\n",
              "       base_model_id='',\n",
              "       version='exp_1206',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (December 6th, 2024) of Gemini.',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-exp-1121',\n",
              "       base_model_id='',\n",
              "       version='exp-1206',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (December 6th, 2024) of Gemini.',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-exp-1114',\n",
              "       base_model_id='',\n",
              "       version='exp-1206',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (December 6th, 2024) of Gemini.',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.0-flash-thinking-exp',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash Thinking Experimental',\n",
              "       description='Gemini 2.0 Flash Thinking Experimental',\n",
              "       input_token_limit=32767,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.0-flash-thinking-exp-1219',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash Thinking Experimental',\n",
              "       description='Gemini 2.0 Flash Thinking Experimental',\n",
              "       input_token_limit=32767,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/learnlm-1.5-pro-experimental',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='LearnLM 1.5 Pro Experimental',\n",
              "       description=('Alias that points to the most recent stable version of Gemini 1.5 Pro, our '\n",
              "                    'mid-size multimodal model that supports up to 2 million tokens.'),\n",
              "       input_token_limit=32767,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/embedding-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Embedding 001',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=2048,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedContent'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/text-embedding-004',\n",
              "       base_model_id='',\n",
              "       version='004',\n",
              "       display_name='Text Embedding 004',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=2048,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedContent'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/aqa',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Model that performs Attributed Question Answering.',\n",
              "       description=('Model trained to return answers to questions that are grounded in provided '\n",
              "                    'sources, along with estimating answerable probability.'),\n",
              "       input_token_limit=7168,\n",
              "       output_token_limit=1024,\n",
              "       supported_generation_methods=['generateAnswer'],\n",
              "       temperature=0.2,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=40)]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For Example\n",
        "from typing import Dict\n",
        "\n",
        "result : Dict = genai.embed_content(\n",
        "    model=\"models/text-embedding-004\",\n",
        "    content=[\n",
        "        \"What is the meaning of life?\",\n",
        "        \"How much wood would a woodchuck chuck?\",\n",
        "        \"How does the brain work?\",\n",
        "    ],\n",
        "    task_type=\"retrieval_document\",\n",
        "    title=\"Embedding of list of strings\",\n",
        ")\n",
        "\n",
        "# A list of inputs > A list of vectors output\n",
        "for v in result[\"embedding\"]:\n",
        "    print(str(v)[:50], \"... TRIMMED ...\", len(v))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "kU3El7yFVshy",
        "outputId": "ce036f6e-b6e8-40ba-9b7b-886ba11caff5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.036453027, 0.033254996, -0.03970925, -0.002628 ... TRIMMED ... 768\n",
            "[-0.01591948, 0.032582663, -0.081024624, -0.011298 ... TRIMMED ... 768\n",
            "[0.00037063024, 0.03763057, -0.122695684, -0.00951 ... TRIMMED ... 768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(result['embedding'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oalm6PwV3F6",
        "outputId": "0bda577b-48f0-445e-d2cf-fdfea9f2914f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -qU langchain-pinecone"
      ],
      "metadata": {
        "id": "TVE5v7JEWCtw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "511df2b6-81c6-42b2-e155-535addea9052"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/427.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.3/427.3 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/87.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.3/50.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install python-docx"
      ],
      "metadata": {
        "id": "B4nF6h2UlDQt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ad58d07-9a7f-47d5-b981-442f566060af"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/244.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m235.5/244.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import Document\n",
        "\n",
        "documents = [\n",
        "    Document(\n",
        "        page_content=\"Dogs are great companions, known for their loyalty and friendliness.\",\n",
        "        metadata={\"source\": \"mammal-pets-doc\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Cats are independent pets that often enjoy their own space.\",\n",
        "        metadata={\"source\": \"mammal-pets-doc\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Goldfish are popular pets for beginners, requiring relatively simple care.\",\n",
        "        metadata={\"source\": \"fish-pets-doc\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Parrots are intelligent birds capable of mimicking human speech.\",\n",
        "        metadata={\"source\": \"bird-pets-doc\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Rabbits are social animals that need plenty of space to hop around.\",\n",
        "        metadata={\"source\": \"mammal-pets-doc\"},\n",
        "    ),\n",
        "]\n"
      ],
      "metadata": {
        "id": "vjufPxnDjxLE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from docx import Document\n",
        "\n",
        "# Create a new Word document\n",
        "doc = Document()\n",
        "\n",
        "# Add a title\n",
        "doc.add_heading('Pet Information', 0)\n",
        "\n",
        "# Loop through the documents and add their content to the Word file\n",
        "for document in documents:\n",
        "    doc.add_heading(document.metadata[\"source\"], level=1)\n",
        "    doc.add_paragraph(document.page_content)\n",
        "\n",
        "# Save the Word document\n",
        "doc.save(\"/content/pet_information.docx\")\n"
      ],
      "metadata": {
        "id": "oHiaacaOj5Nw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrcyW7nJmUMp",
        "outputId": "4da28541-95dc-4d57-a76b-1170d467d83c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(metadata={'source': 'mammal-pets-doc'}, page_content='Dogs are great companions, known for their loyalty and friendliness.'), Document(metadata={'source': 'mammal-pets-doc'}, page_content='Cats are independent pets that often enjoy their own space.'), Document(metadata={'source': 'fish-pets-doc'}, page_content='Goldfish are popular pets for beginners, requiring relatively simple care.'), Document(metadata={'source': 'bird-pets-doc'}, page_content='Parrots are intelligent birds capable of mimicking human speech.'), Document(metadata={'source': 'mammal-pets-doc'}, page_content='Rabbits are social animals that need plenty of space to hop around.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq langchain-google-genai"
      ],
      "metadata": {
        "id": "nlSNPmwVWPAm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1111c843-6167-42ef-8737-bfb3c8508343"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.5/41.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\",\n",
        "                                          task_type=\"retrieval_document\",\n",
        "                                          google_api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "# embeddings.embed_query(\"What's our Q1 revenue?\")"
      ],
      "metadata": {
        "id": "uDZU1jvTWSEG"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings.embed_query(\"What's our Q1 revenue?\")"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nosmAwuuWVI5",
        "outputId": "46bad241-3269-47cf-8057-ef58dfac1ce5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.022226594388484955,\n",
              " -0.005298603791743517,\n",
              " -0.03638031706213951,\n",
              " -0.022343235090374947,\n",
              " 0.021077357232570648,\n",
              " 0.026357078924775124,\n",
              " -0.005140196997672319,\n",
              " -0.0047151208855211735,\n",
              " -0.020215705037117004,\n",
              " 0.004603210836648941,\n",
              " 0.021817319095134735,\n",
              " 0.009138683788478374,\n",
              " 0.10358211398124695,\n",
              " -0.005005174316465855,\n",
              " 0.01096127089112997,\n",
              " -0.01904454454779625,\n",
              " 0.005782195366919041,\n",
              " -0.015201744623482227,\n",
              " -0.13191628456115723,\n",
              " -0.0029817058239132166,\n",
              " 0.01769891194999218,\n",
              " -0.010750621557235718,\n",
              " 0.0003200707142241299,\n",
              " -0.0002848370058927685,\n",
              " -0.029578616842627525,\n",
              " -0.031128263100981712,\n",
              " -0.02592356875538826,\n",
              " -0.0026727376971393824,\n",
              " -0.014347424730658531,\n",
              " -0.013856600970029831,\n",
              " 0.04075340926647186,\n",
              " 0.0566372312605381,\n",
              " -0.025405442342162132,\n",
              " -0.07057256251573563,\n",
              " -0.013354412280023098,\n",
              " 0.01110386848449707,\n",
              " -0.017656734213232994,\n",
              " 0.049004241824150085,\n",
              " 0.05370621383190155,\n",
              " -0.06309186667203903,\n",
              " -0.04680578410625458,\n",
              " 0.04269225150346756,\n",
              " -0.0376492477953434,\n",
              " 0.034613508731126785,\n",
              " 0.015920504927635193,\n",
              " -0.005015942268073559,\n",
              " -0.019627569243311882,\n",
              " 0.022009341046214104,\n",
              " -0.021308129653334618,\n",
              " 0.02998981811106205,\n",
              " 0.004539167508482933,\n",
              " -0.005820050369948149,\n",
              " -0.02866225689649582,\n",
              " 0.01844654232263565,\n",
              " -0.036423005163669586,\n",
              " -0.0192630086094141,\n",
              " 0.000625443528406322,\n",
              " -0.02209116891026497,\n",
              " 0.07254112511873245,\n",
              " 0.007985727861523628,\n",
              " 0.031146729364991188,\n",
              " 0.0017971416236832738,\n",
              " 0.029390238225460052,\n",
              " -0.025428995490074158,\n",
              " 0.023132970556616783,\n",
              " -0.0477542020380497,\n",
              " 0.04042516648769379,\n",
              " -0.00842307973653078,\n",
              " -0.1012738049030304,\n",
              " 0.010009721852838993,\n",
              " -0.010360919870436192,\n",
              " 0.020699750632047653,\n",
              " -0.00441768066957593,\n",
              " -0.022069325670599937,\n",
              " 0.009540443308651447,\n",
              " -0.023630358278751373,\n",
              " -0.0036314574535936117,\n",
              " -0.05932920053601265,\n",
              " 0.02010798454284668,\n",
              " 0.07272153347730637,\n",
              " -0.04684885963797569,\n",
              " 0.03593156859278679,\n",
              " 0.09907948225736618,\n",
              " 0.05712980404496193,\n",
              " -0.007801423314958811,\n",
              " -0.005544858984649181,\n",
              " -0.0010974528267979622,\n",
              " -0.07117077708244324,\n",
              " -0.06650371849536896,\n",
              " -0.025325743481516838,\n",
              " 0.1129743903875351,\n",
              " -0.01649031788110733,\n",
              " 0.002227967604994774,\n",
              " -0.015962544828653336,\n",
              " 0.061657898128032684,\n",
              " -0.05086567997932434,\n",
              " -0.11666125804185867,\n",
              " -0.09163300693035126,\n",
              " 0.12350181490182877,\n",
              " 0.06353986263275146,\n",
              " -0.006148841697722673,\n",
              " -0.017936132848262787,\n",
              " 0.003580193966627121,\n",
              " -0.04850807785987854,\n",
              " 0.06502830982208252,\n",
              " 0.026402536779642105,\n",
              " -0.01779032126069069,\n",
              " -0.030816009268164635,\n",
              " -0.017839552834630013,\n",
              " 0.03300207108259201,\n",
              " -0.03641283139586449,\n",
              " -0.027865102514624596,\n",
              " 0.0037986040115356445,\n",
              " -0.01583228074014187,\n",
              " -0.01765415444970131,\n",
              " 0.008917557075619698,\n",
              " -0.05031103268265724,\n",
              " -0.012929655611515045,\n",
              " -0.04997552931308746,\n",
              " 0.04426252469420433,\n",
              " 0.02112569287419319,\n",
              " 0.003944985568523407,\n",
              " -0.0005972199141979218,\n",
              " 0.08013460040092468,\n",
              " 0.038118500262498856,\n",
              " 0.00431292736902833,\n",
              " 0.016635878011584282,\n",
              " -0.005197727587074041,\n",
              " -0.06309716403484344,\n",
              " -0.0533871054649353,\n",
              " 0.04573320597410202,\n",
              " -0.002932108473032713,\n",
              " 0.0015490050427615643,\n",
              " -0.009175538085401058,\n",
              " 0.008502489887177944,\n",
              " -0.03620068356394768,\n",
              " 0.07962542772293091,\n",
              " -0.010982080362737179,\n",
              " -0.003842094447463751,\n",
              " 0.049310311675071716,\n",
              " 0.005975356791168451,\n",
              " -0.06039266660809517,\n",
              " -0.058337125927209854,\n",
              " 0.027955640107393265,\n",
              " -0.017164405435323715,\n",
              " -0.016277456656098366,\n",
              " 0.0003573615394998342,\n",
              " 0.03726593032479286,\n",
              " -0.0520293153822422,\n",
              " -0.027596039697527885,\n",
              " -0.03356313705444336,\n",
              " -0.02832038700580597,\n",
              " 0.0347348116338253,\n",
              " -0.05363476648926735,\n",
              " 0.033174581825733185,\n",
              " -0.003278065240010619,\n",
              " 0.01700962707400322,\n",
              " -0.015585160814225674,\n",
              " 0.05431152135133743,\n",
              " 0.019372470676898956,\n",
              " 0.020818544551730156,\n",
              " -0.03509155288338661,\n",
              " -0.01725299470126629,\n",
              " 0.013189548626542091,\n",
              " -0.030227405950427055,\n",
              " 0.00041337075526826084,\n",
              " -0.006035864353179932,\n",
              " -0.03448965772986412,\n",
              " 0.030990615487098694,\n",
              " 0.024038389325141907,\n",
              " -0.0504787340760231,\n",
              " -0.038194265216588974,\n",
              " -0.036962538957595825,\n",
              " -0.14940288662910461,\n",
              " -0.0007298281998373568,\n",
              " 0.055891916155815125,\n",
              " -0.020810334011912346,\n",
              " -0.0516541451215744,\n",
              " -0.06311966478824615,\n",
              " -0.04856238514184952,\n",
              " 0.09279011934995651,\n",
              " 0.045674778521060944,\n",
              " -0.03071071207523346,\n",
              " -0.05175532400608063,\n",
              " 0.06351175159215927,\n",
              " 0.035107262432575226,\n",
              " 0.003562805475667119,\n",
              " -0.002338508376851678,\n",
              " 0.03157693147659302,\n",
              " 0.03579365834593773,\n",
              " -0.008538076654076576,\n",
              " 0.012400281615555286,\n",
              " 0.010713991709053516,\n",
              " 0.02715781331062317,\n",
              " 0.012414165772497654,\n",
              " 0.0010523564415052533,\n",
              " 0.010438244789838791,\n",
              " -0.031467683613300323,\n",
              " -0.02394324354827404,\n",
              " -0.07128044217824936,\n",
              " 0.009866570122539997,\n",
              " -0.023720629513263702,\n",
              " 0.0031700474210083485,\n",
              " -0.027402183040976524,\n",
              " -0.013245276175439358,\n",
              " -0.006096801720559597,\n",
              " -0.060405317693948746,\n",
              " -0.06314291059970856,\n",
              " -0.04098212718963623,\n",
              " 0.005133878439664841,\n",
              " 0.02173513174057007,\n",
              " 0.02076464518904686,\n",
              " -0.05143316462635994,\n",
              " -0.054314836859703064,\n",
              " 0.03233519569039345,\n",
              " 0.0077841151505708694,\n",
              " 0.08499736338853836,\n",
              " -0.008963796310126781,\n",
              " 0.042318642139434814,\n",
              " -0.03281738609075546,\n",
              " 0.04486547410488129,\n",
              " -0.008745422586798668,\n",
              " 0.041027218103408813,\n",
              " 0.019976599141955376,\n",
              " 0.013466877862811089,\n",
              " 0.026504043489694595,\n",
              " -0.016461839899420738,\n",
              " -0.0009097418515011668,\n",
              " 0.0008154042880050838,\n",
              " -0.042372964322566986,\n",
              " 0.04173005744814873,\n",
              " 0.018633171916007996,\n",
              " 0.00033317203633487225,\n",
              " 0.054529935121536255,\n",
              " -0.06457182765007019,\n",
              " 0.05790901184082031,\n",
              " 0.01392583828419447,\n",
              " -0.005332334898412228,\n",
              " -0.013601488433778286,\n",
              " -0.03383253142237663,\n",
              " 0.0019590482115745544,\n",
              " 0.031120290979743004,\n",
              " 0.018930727615952492,\n",
              " -0.003952922765165567,\n",
              " 0.006722755264490843,\n",
              " -0.015813102945685387,\n",
              " 0.03396785631775856,\n",
              " 0.04313438758254051,\n",
              " -0.010516662150621414,\n",
              " -0.05007290095090866,\n",
              " -0.04662228375673294,\n",
              " -0.004197621252387762,\n",
              " 0.011467332020401955,\n",
              " -0.014158390462398529,\n",
              " -0.06800619512796402,\n",
              " -0.028347516432404518,\n",
              " 0.017755230888724327,\n",
              " -0.02370121143758297,\n",
              " 0.004076113924384117,\n",
              " 0.002730700885877013,\n",
              " 0.039065469056367874,\n",
              " -0.04134557023644447,\n",
              " -0.00876109953969717,\n",
              " -0.07670732587575912,\n",
              " -0.033366911113262177,\n",
              " -0.09219925105571747,\n",
              " -0.0348145067691803,\n",
              " -0.029225410893559456,\n",
              " 0.033192265778779984,\n",
              " -0.007357532158493996,\n",
              " 0.028007306158542633,\n",
              " -0.0150271225720644,\n",
              " -0.041268959641456604,\n",
              " -0.01638699322938919,\n",
              " 0.00403737323358655,\n",
              " -0.002469941508024931,\n",
              " -0.007841832935810089,\n",
              " 0.0177740640938282,\n",
              " -0.02536865510046482,\n",
              " -0.008975150994956493,\n",
              " 0.02695218287408352,\n",
              " -0.0039434898644685745,\n",
              " 0.025709304958581924,\n",
              " -0.027457013726234436,\n",
              " 0.024118226021528244,\n",
              " -0.016164502128958702,\n",
              " 0.0038857334293425083,\n",
              " 0.03964969888329506,\n",
              " 0.01868283748626709,\n",
              " -0.03204793483018875,\n",
              " 0.033737361431121826,\n",
              " 0.018496528267860413,\n",
              " -0.012237520888447762,\n",
              " -0.02380858175456524,\n",
              " 0.04518953338265419,\n",
              " 0.04645271599292755,\n",
              " 0.041205666959285736,\n",
              " 0.02620420604944229,\n",
              " -0.018072374165058136,\n",
              " 0.0228431299328804,\n",
              " 0.03255779668688774,\n",
              " 0.016500938683748245,\n",
              " -0.0006749919266439974,\n",
              " 0.06100503355264664,\n",
              " 0.0528046153485775,\n",
              " -0.0004929970018565655,\n",
              " -0.023420125246047974,\n",
              " -0.04012926667928696,\n",
              " -0.05476916953921318,\n",
              " 0.016112204641103745,\n",
              " -0.02649225853383541,\n",
              " -0.012888511642813683,\n",
              " -0.03166413679718971,\n",
              " -0.056880801916122437,\n",
              " -0.0109866326674819,\n",
              " -0.020870579406619072,\n",
              " -0.1717415750026703,\n",
              " -0.025935528799891472,\n",
              " -0.025528550148010254,\n",
              " -0.05869751051068306,\n",
              " 0.03541422635316849,\n",
              " -0.003080914728343487,\n",
              " -0.014614789746701717,\n",
              " -0.0006194908055476844,\n",
              " 0.03932230547070503,\n",
              " 0.02399362064898014,\n",
              " 0.016133887693285942,\n",
              " 0.010709953494369984,\n",
              " -0.02683279663324356,\n",
              " -0.012185994535684586,\n",
              " 0.0006029371870681643,\n",
              " -0.00311285094358027,\n",
              " -0.01579124480485916,\n",
              " -0.045539114624261856,\n",
              " 0.005493211094290018,\n",
              " 0.04450572282075882,\n",
              " -0.04505062848329544,\n",
              " 0.02615918219089508,\n",
              " 0.07189852744340897,\n",
              " 0.024378430098295212,\n",
              " 0.053511086851358414,\n",
              " 0.05234937742352486,\n",
              " 0.020721565932035446,\n",
              " 0.03115910477936268,\n",
              " -0.028591973707079887,\n",
              " -0.03270052373409271,\n",
              " 0.0319538451731205,\n",
              " 0.030387550592422485,\n",
              " 0.015228117816150188,\n",
              " 0.019115425646305084,\n",
              " 0.019179655238986015,\n",
              " 0.06175478920340538,\n",
              " 0.02296931855380535,\n",
              " -0.04913710057735443,\n",
              " -0.017372604459524155,\n",
              " -0.012395682744681835,\n",
              " 0.044948510825634,\n",
              " 0.00014537322567775846,\n",
              " 0.02239818312227726,\n",
              " -0.006638768594712019,\n",
              " -0.005050745792686939,\n",
              " -0.0034483238123357296,\n",
              " -0.02906573750078678,\n",
              " -0.009281271137297153,\n",
              " 0.026370424777269363,\n",
              " 0.009885013103485107,\n",
              " -0.011068258434534073,\n",
              " 0.04966338723897934,\n",
              " -0.024370940402150154,\n",
              " -0.014899887144565582,\n",
              " -0.008201101794838905,\n",
              " -0.01651821844279766,\n",
              " 0.037150442600250244,\n",
              " 0.022930391132831573,\n",
              " 0.020134922116994858,\n",
              " -0.035318441689014435,\n",
              " -0.04148374870419502,\n",
              " 0.009557006880640984,\n",
              " 0.0014441476669162512,\n",
              " 0.008513247594237328,\n",
              " 0.024695223197340965,\n",
              " -0.0019849161617457867,\n",
              " -0.02113516628742218,\n",
              " 0.04506813734769821,\n",
              " -0.0399811714887619,\n",
              " 0.04906802251935005,\n",
              " -0.05832919850945473,\n",
              " -0.009916120208799839,\n",
              " -0.01977156102657318,\n",
              " -0.025504782795906067,\n",
              " -0.022556329146027565,\n",
              " 0.06419715285301208,\n",
              " 0.048336174339056015,\n",
              " 0.008737850934267044,\n",
              " 0.008948620408773422,\n",
              " 0.06744468212127686,\n",
              " -0.023545198142528534,\n",
              " -0.0013568163849413395,\n",
              " 0.0013678348623216152,\n",
              " -0.022539660334587097,\n",
              " -0.02840825356543064,\n",
              " -0.02082819677889347,\n",
              " 0.04918902739882469,\n",
              " -0.057377830147743225,\n",
              " -0.04200776293873787,\n",
              " -0.005824520718306303,\n",
              " 0.06274418532848358,\n",
              " -0.013126898556947708,\n",
              " 0.0006589803961105645,\n",
              " -0.011696905829012394,\n",
              " 0.028594505041837692,\n",
              " -0.0388314388692379,\n",
              " -0.03157133609056473,\n",
              " 0.005914303474128246,\n",
              " -0.03562306612730026,\n",
              " -0.001563332392834127,\n",
              " 0.03551714867353439,\n",
              " -0.036134302616119385,\n",
              " 0.0084008714184165,\n",
              " -0.0032738728914409876,\n",
              " -0.018211480230093002,\n",
              " 0.00979344081133604,\n",
              " 0.03228900209069252,\n",
              " -0.054349496960639954,\n",
              " 0.022075660526752472,\n",
              " -0.04583057016134262,\n",
              " -0.009438256733119488,\n",
              " 0.06111092120409012,\n",
              " 0.013843490742146969,\n",
              " 0.0018677449552342296,\n",
              " -0.01139054074883461,\n",
              " 0.04884447157382965,\n",
              " -0.013501963578164577,\n",
              " 0.07635505497455597,\n",
              " -0.02703477069735527,\n",
              " 0.04791810363531113,\n",
              " -0.009883210994303226,\n",
              " 0.015428111888468266,\n",
              " 0.008399995975196362,\n",
              " -0.008611720986664295,\n",
              " 0.00662738224491477,\n",
              " 0.011833206750452518,\n",
              " 0.07719404250383377,\n",
              " 0.03778831288218498,\n",
              " -0.0070171658881008625,\n",
              " 0.02891252003610134,\n",
              " 0.03387701138854027,\n",
              " 0.03604893758893013,\n",
              " -0.044774994254112244,\n",
              " -0.016598299145698547,\n",
              " 0.022106053307652473,\n",
              " -0.010231797583401203,\n",
              " 0.028759395703673363,\n",
              " -0.028195179998874664,\n",
              " -0.07361113280057907,\n",
              " -0.005315231624990702,\n",
              " 0.0027673179283738136,\n",
              " 0.0008430378511548042,\n",
              " -0.01540814246982336,\n",
              " -0.0002712723216973245,\n",
              " -0.0002922312414739281,\n",
              " -0.03168077394366264,\n",
              " 0.0438140444457531,\n",
              " 0.048403725028038025,\n",
              " -0.022460874170064926,\n",
              " -0.0294642336666584,\n",
              " 0.018181294202804565,\n",
              " 0.02315670996904373,\n",
              " -0.07432514429092407,\n",
              " 0.10074174404144287,\n",
              " 0.05891750380396843,\n",
              " 0.006482315249741077,\n",
              " 0.01495268288999796,\n",
              " -0.008060482330620289,\n",
              " -0.03139793872833252,\n",
              " 0.007842696271836758,\n",
              " 0.0010698714759200811,\n",
              " -0.0164495762437582,\n",
              " -0.06137741729617119,\n",
              " -0.02063516154885292,\n",
              " -0.04090778902173042,\n",
              " -0.029538316652178764,\n",
              " -0.032538704574108124,\n",
              " 0.051953304558992386,\n",
              " 0.05248884856700897,\n",
              " -0.02072363719344139,\n",
              " -0.01405224110931158,\n",
              " -0.003475580597296357,\n",
              " 0.04016716033220291,\n",
              " 0.00546665396541357,\n",
              " 0.00217344774864614,\n",
              " 0.009110313840210438,\n",
              " -0.009502151980996132,\n",
              " -0.05581735819578171,\n",
              " -0.033668216317892075,\n",
              " -0.010227514430880547,\n",
              " 0.06852731108665466,\n",
              " -0.01525798812508583,\n",
              " -0.005365421995520592,\n",
              " 0.02133900299668312,\n",
              " 0.06461446732282639,\n",
              " 0.03550137206912041,\n",
              " -0.014492698013782501,\n",
              " -0.04751083627343178,\n",
              " -0.04049893468618393,\n",
              " -0.026478130370378494,\n",
              " -0.05369015410542488,\n",
              " -0.01672971062362194,\n",
              " 0.04460546001791954,\n",
              " -0.008905229158699512,\n",
              " 0.01634923368692398,\n",
              " -0.05081283673644066,\n",
              " 0.012939571402966976,\n",
              " 0.024705352261662483,\n",
              " 0.002017729450017214,\n",
              " 0.028308067470788956,\n",
              " -0.04301763325929642,\n",
              " 0.019106844440102577,\n",
              " -0.027899911627173424,\n",
              " -0.021623872220516205,\n",
              " -0.09576532244682312,\n",
              " -0.016514046117663383,\n",
              " 0.04532146081328392,\n",
              " 0.015003633685410023,\n",
              " 0.03911326453089714,\n",
              " -0.02569311112165451,\n",
              " -0.01687788777053356,\n",
              " -0.0037922943010926247,\n",
              " 0.014922797679901123,\n",
              " -0.030047044157981873,\n",
              " 0.0139529500156641,\n",
              " 0.0706014633178711,\n",
              " 0.04022131860256195,\n",
              " 0.02678685262799263,\n",
              " -0.013339661993086338,\n",
              " 0.013184675015509129,\n",
              " 0.015739602968096733,\n",
              " -0.0005479677929542959,\n",
              " -0.0008281019399873912,\n",
              " 0.03891754522919655,\n",
              " 0.01091068983078003,\n",
              " -0.010017975233495235,\n",
              " 0.01539947185665369,\n",
              " 0.03664243221282959,\n",
              " 0.06003282219171524,\n",
              " 0.024531396105885506,\n",
              " 0.02325248159468174,\n",
              " 0.002606420312076807,\n",
              " -0.002281819237396121,\n",
              " 0.06610080599784851,\n",
              " -0.019976487383246422,\n",
              " -0.037230413407087326,\n",
              " 0.005987548269331455,\n",
              " -0.009566159918904305,\n",
              " 0.03991018980741501,\n",
              " -0.023638539016246796,\n",
              " 0.009327002801001072,\n",
              " -0.03074316307902336,\n",
              " 0.00963535625487566,\n",
              " -0.048613689839839935,\n",
              " 0.04799695685505867,\n",
              " -0.000598920276388526,\n",
              " 0.04262528941035271,\n",
              " -0.03033081628382206,\n",
              " 0.007082917261868715,\n",
              " -0.006616163533180952,\n",
              " 0.040928278118371964,\n",
              " 0.11593393236398697,\n",
              " -0.014434943906962872,\n",
              " -0.047835882753133774,\n",
              " 0.06434575468301773,\n",
              " -0.002134900074452162,\n",
              " -0.03312677517533302,\n",
              " -0.05343375727534294,\n",
              " -0.0009660557261668146,\n",
              " 0.006068421993404627,\n",
              " -0.03528643399477005,\n",
              " 0.006547562777996063,\n",
              " 0.02679385617375374,\n",
              " -0.030030418187379837,\n",
              " 0.026691636070609093,\n",
              " 0.009977879002690315,\n",
              " 0.039576999843120575,\n",
              " -0.028455328196287155,\n",
              " 0.021867915987968445,\n",
              " 0.014057076536118984,\n",
              " -0.0229551550000906,\n",
              " -0.002692192792892456,\n",
              " -0.02359931543469429,\n",
              " -0.017776964232325554,\n",
              " 0.029828563332557678,\n",
              " 0.02786264382302761,\n",
              " -0.002845627488568425,\n",
              " -0.051545631140470505,\n",
              " 0.05039771646261215,\n",
              " 0.008569895289838314,\n",
              " -0.00791830476373434,\n",
              " 0.029144246131181717,\n",
              " 0.04806222394108772,\n",
              " 0.031230688095092773,\n",
              " -0.011829673312604427,\n",
              " 0.00151498569175601,\n",
              " 0.07027042657136917,\n",
              " -0.002682527992874384,\n",
              " 0.022203685715794563,\n",
              " -0.004109181929379702,\n",
              " -0.023640239611268044,\n",
              " -0.0235796719789505,\n",
              " 0.018984494730830193,\n",
              " -0.058766014873981476,\n",
              " 0.007057194132357836,\n",
              " 0.06867268681526184,\n",
              " -0.03264006972312927,\n",
              " 0.006247065495699644,\n",
              " -0.02806328982114792,\n",
              " -0.019323956221342087,\n",
              " -0.04795915260910988,\n",
              " -0.03528982773423195,\n",
              " -0.015628594905138016,\n",
              " 0.0029640451539307833,\n",
              " 0.058127231895923615,\n",
              " 0.005704561714082956,\n",
              " 0.05814940482378006,\n",
              " -0.015527062118053436,\n",
              " -0.040549613535404205,\n",
              " -0.0017674390692263842,\n",
              " -0.02478841133415699,\n",
              " 0.026005355641245842,\n",
              " 0.002651791088283062,\n",
              " 0.00028849218506366014,\n",
              " -0.0037094790022820234,\n",
              " 0.0035191054921597242,\n",
              " 0.03706856817007065,\n",
              " 0.01021308358758688,\n",
              " -0.028849299997091293,\n",
              " 0.029281601309776306,\n",
              " 0.03351256996393204,\n",
              " 0.016395695507526398,\n",
              " -0.014265250414609909,\n",
              " -0.03133294731378555,\n",
              " 0.020643722265958786,\n",
              " -0.012067580595612526,\n",
              " 0.016430404037237167,\n",
              " -0.014521948993206024,\n",
              " 0.006077679339796305,\n",
              " 0.012200171127915382,\n",
              " 0.05724212899804115,\n",
              " 0.021785903722047806,\n",
              " 0.0033629846293479204,\n",
              " 0.018275104463100433,\n",
              " 0.04906865209341049,\n",
              " 0.05134385824203491,\n",
              " -0.03855302557349205,\n",
              " -0.03504388406872749,\n",
              " -0.011221746914088726,\n",
              " 0.04318196326494217,\n",
              " -0.07632608711719513,\n",
              " 0.0654618963599205,\n",
              " 0.0200798436999321,\n",
              " 0.017932672053575516,\n",
              " -0.01179832685738802,\n",
              " -0.06265805661678314,\n",
              " -0.030083470046520233,\n",
              " 0.0727839395403862,\n",
              " 0.0018455148674547672,\n",
              " -0.03883303329348564,\n",
              " -0.011760012246668339,\n",
              " 0.006958144251257181,\n",
              " -0.017057977616786957,\n",
              " -0.0445873960852623,\n",
              " -0.003946118988096714,\n",
              " -0.023100443184375763,\n",
              " -0.03872853145003319,\n",
              " -0.0015055370749905705,\n",
              " 0.013283141888678074,\n",
              " 0.040065377950668335,\n",
              " 0.01946759782731533,\n",
              " -0.03555799275636673,\n",
              " -0.029442381113767624,\n",
              " 0.03796841576695442,\n",
              " 0.02085723914206028,\n",
              " -0.04206998646259308,\n",
              " -0.002140696858987212,\n",
              " -0.013470678590238094,\n",
              " 0.061021555215120316,\n",
              " 0.0002738046459853649,\n",
              " 0.048743586987257004,\n",
              " -0.04036416485905647,\n",
              " -0.040941864252090454,\n",
              " 0.039771679788827896,\n",
              " 0.01981128565967083,\n",
              " 0.008479202166199684,\n",
              " -0.010048742406070232,\n",
              " -0.014563866890966892,\n",
              " -0.05084305629134178,\n",
              " 0.030454088002443314,\n",
              " -0.03311372920870781,\n",
              " 0.01673833280801773,\n",
              " -0.02165714092552662,\n",
              " 0.00804855115711689,\n",
              " -0.042994823306798935,\n",
              " 0.02133169397711754,\n",
              " -0.07865961641073227,\n",
              " -0.01728239841759205,\n",
              " 0.008329388685524464,\n",
              " 0.005574984010308981,\n",
              " 0.023211302235722542,\n",
              " 0.018734091892838478,\n",
              " -0.03522956743836403,\n",
              " -0.006770686246454716,\n",
              " -0.011416571214795113,\n",
              " 0.008358778432011604,\n",
              " 0.024552639573812485,\n",
              " -0.01443037111312151,\n",
              " 0.01326853409409523,\n",
              " -0.01617586426436901,\n",
              " 0.041666094213724136,\n",
              " -0.00015066255582496524,\n",
              " 0.05549973249435425,\n",
              " 0.04284822940826416,\n",
              " 0.005649875849485397,\n",
              " -0.014356370083987713,\n",
              " 0.043151210993528366,\n",
              " 0.062412433326244354,\n",
              " 0.057989880442619324,\n",
              " -0.017404351383447647,\n",
              " -0.0721379816532135,\n",
              " -0.036617379635572433,\n",
              " -0.01191561110317707,\n",
              " 0.06183181703090668,\n",
              " 0.09381899237632751,\n",
              " -0.04621182382106781,\n",
              " -0.033794719725847244,\n",
              " 0.0001599716633791104,\n",
              " -7.069926505209878e-05,\n",
              " -0.009579337202012539,\n",
              " -0.010989508591592312,\n",
              " -0.030490431934595108,\n",
              " -0.0316646508872509,\n",
              " -0.05164915323257446,\n",
              " 0.04517431929707527,\n",
              " -0.01321561262011528,\n",
              " -0.03659551218152046,\n",
              " -0.028218768537044525,\n",
              " 0.02055307850241661,\n",
              " 0.007009559776633978,\n",
              " -0.0026032612659037113,\n",
              " -0.0190665815025568,\n",
              " -0.010799313895404339,\n",
              " -0.02404855750501156,\n",
              " -0.058357782661914825,\n",
              " 0.038610320538282394,\n",
              " 0.010915194638073444,\n",
              " 0.018968859687447548,\n",
              " 0.015082031488418579,\n",
              " -0.011996623128652573,\n",
              " 0.048484522849321365,\n",
              " -0.001639144727960229,\n",
              " -0.0009043152676895261,\n",
              " -0.0029099348466843367,\n",
              " -0.007621645461767912,\n",
              " 0.0748806968331337,\n",
              " 0.02242785319685936,\n",
              " 0.01824522390961647,\n",
              " -0.06470713764429092,\n",
              " -0.007027271669358015,\n",
              " 0.06323617696762085,\n",
              " -0.007570209912955761]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(embeddings.embed_query(\"What's our Q1 revenue?\")) # So, you can see that given dimension of prompt is 768"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwdYSdwxL7_j",
        "outputId": "9d0bb9e4-04b0-4db5-e762-c7b6045fc5bc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "\n",
        "os.environ[\"PINECONE_API_KEY\"] = userdata.get(\"PINECONE_API_KEY\")\n",
        "\n",
        "pinecone_api_key = os.environ[\"PINECONE_API_KEY\"]\n",
        "\n",
        "pc = Pinecone(api_key=pinecone_api_key)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "DL6TZv9dWYry"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "\n",
        "index_name = \"rag2-piaic-bilal\"  # change if desired\n",
        "\n",
        "existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
        "\n",
        "if index_name not in existing_indexes:\n",
        "    pc.create_index(\n",
        "        name=index_name,\n",
        "        dimension=768,\n",
        "        metric=\"cosine\",\n",
        "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
        "    )\n",
        "    while not pc.describe_index(index_name).status[\"ready\"]:\n",
        "        time.sleep(1)\n",
        "\n",
        "index = pc.Index(index_name)"
      ],
      "metadata": {
        "id": "EMNl2OoeW_Ey"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_pinecone import PineconeVectorStore\n",
        "\n",
        "vectorstore = PineconeVectorStore.from_documents(\n",
        "    documents=documents,\n",
        "    embedding=embeddings,\n",
        "    index_name=index_name,\n",
        ")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "0FUy6AUrY3eU"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(dir(vectorstore)) # Check list of directories of vector store"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32B2cG_SZFqm",
        "outputId": "43bee2f4-c122-4b24-aa22-7dc0bfb66381"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__abstractmethods__',\n",
              " '__annotations__',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__slots__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_abc_impl',\n",
              " '_asimilarity_search_with_relevance_scores',\n",
              " '_cosine_relevance_score_fn',\n",
              " '_embedding',\n",
              " '_euclidean_relevance_score_fn',\n",
              " '_get_retriever_tags',\n",
              " '_index',\n",
              " '_max_inner_product_relevance_score_fn',\n",
              " '_namespace',\n",
              " '_select_relevance_score_fn',\n",
              " '_similarity_search_with_relevance_scores',\n",
              " '_text_key',\n",
              " 'aadd_documents',\n",
              " 'aadd_texts',\n",
              " 'add_documents',\n",
              " 'add_texts',\n",
              " 'adelete',\n",
              " 'afrom_documents',\n",
              " 'afrom_texts',\n",
              " 'aget_by_ids',\n",
              " 'amax_marginal_relevance_search',\n",
              " 'amax_marginal_relevance_search_by_vector',\n",
              " 'as_retriever',\n",
              " 'asearch',\n",
              " 'asimilarity_search',\n",
              " 'asimilarity_search_by_vector',\n",
              " 'asimilarity_search_with_relevance_scores',\n",
              " 'asimilarity_search_with_score',\n",
              " 'delete',\n",
              " 'distance_strategy',\n",
              " 'embeddings',\n",
              " 'from_documents',\n",
              " 'from_existing_index',\n",
              " 'from_texts',\n",
              " 'get_by_ids',\n",
              " 'get_pinecone_index',\n",
              " 'max_marginal_relevance_search',\n",
              " 'max_marginal_relevance_search_by_vector',\n",
              " 'search',\n",
              " 'similarity_search',\n",
              " 'similarity_search_by_vector',\n",
              " 'similarity_search_by_vector_with_score',\n",
              " 'similarity_search_with_relevance_scores',\n",
              " 'similarity_search_with_score']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K40GP5XtZMN6",
        "outputId": "2758bf14-5c7e-4173-f7e0-96329584861c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_pinecone.vectorstores.PineconeVectorStore at 0x7ee358428700>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore.similarity_search(\"fish\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vwd-bhQhZd1E",
        "outputId": "751e8e6d-496c-4b7b-aa21-9f35ceacda08"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='aeebe745-98a2-4cb1-adad-3a2dbb94ac08', metadata={'source': 'fish-pets-doc'}, page_content='Goldfish are popular pets for beginners, requiring relatively simple care.'),\n",
              " Document(id='80d58e84-ecda-48c4-a48e-ed6fed88f91c', metadata={'source': 'fish-pets-doc'}, page_content='Goldfish are popular pets for beginners, requiring relatively simple care.'),\n",
              " Document(id='80a1b030-9b77-40f0-b1a5-d3cc70719cca', metadata={'source': 'fish-pets-doc'}, page_content='Goldfish are popular pets for beginners, requiring relatively simple care.'),\n",
              " Document(id='8ae36850-8b81-4687-ac2e-6928fb18a9cc', metadata={'source': 'fish-pets-doc'}, page_content='Goldfish are popular pets for beginners, requiring relatively simple care.')]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "await vectorstore.asimilarity_search(\"parrot\") # this is asynchronous"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9QxcVYgoHpK",
        "outputId": "922ae000-43ff-461b-eeea-62de35206d7e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='5280beea-c82a-4fac-b961-fb7059a9cffc', metadata={'source': 'bird-pets-doc'}, page_content='Parrots are intelligent birds capable of mimicking human speech.'),\n",
              " Document(id='5158c020-9260-4975-8199-39897aaed40c', metadata={'source': 'bird-pets-doc'}, page_content='Parrots are intelligent birds capable of mimicking human speech.'),\n",
              " Document(id='b19dc457-e00a-4d23-80ac-6e0ff5f78f90', metadata={'source': 'bird-pets-doc'}, page_content='Parrots are intelligent birds capable of mimicking human speech.'),\n",
              " Document(id='3235b68f-49ad-41fa-9069-c46645203f0f', metadata={'source': 'bird-pets-doc'}, page_content='Parrots are intelligent birds capable of mimicking human speech.')]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore.similarity_search_with_score(\"human\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "W32m8Qmapv0F",
        "outputId": "75657dd1-ef7d-4968-ee3b-61dbff6de2d0"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'PineconeVectorStore' object has no attribute 'sizeof'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-adb2f50065c8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvectorstore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msizeof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"human\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'PineconeVectorStore' object has no attribute 'sizeof'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "retriever = RunnableLambda(vectorstore.similarity_search).bind(k=2)  # select top result\n",
        "\n",
        "retriever.batch([\"friendly\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XA3xNmqBsT9n",
        "outputId": "2e2254a6-bd46-40b3-a73a-0a508abe7563"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[Document(id='2f296eaf-4917-46a8-99f6-0a9ef3a589ce', metadata={'source': 'wednesday-task'}, page_content='online class and then free.'),\n",
              "  Document(id='67342470-229b-442b-9f98-126db2dcaaeb', metadata={'source': 'wednesday-task'}, page_content='online class and then free.')]]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\",\n",
        "                             api_key = userdata.get('GOOGLE_API_KEY')\n",
        ")"
      ],
      "metadata": {
        "id": "zE3gyHEktKpH"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(\"What's cat ?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzJ9umlftXje",
        "outputId": "d6a5fbc9-f113-4f53-d1cb-59f2f795f800"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='\"Cat\" refers to a small, furry, domesticated mammal of the family Felidae.  They are known for their independent nature, hunting abilities, and purring.  There are many different breeds of cats, each with varying appearances and temperaments.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-2a076376-0c3f-4bc9-bc8e-6f42bd42b61b-0', usage_metadata={'input_tokens': 6, 'output_tokens': 52, 'total_tokens': 58, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "message = \"\"\"\n",
        "Answer this question using the provided context and some relative information from model.\n",
        "\n",
        "{question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "NeY4S2dHtpnA"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_messages([(\"human\", message)])"
      ],
      "metadata": {
        "id": "_OARxq3NtsMU"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain = {\"context\": retriever, \"question\": RunnablePassthrough()} | prompt | llm\n"
      ],
      "metadata": {
        "id": "kaFpPQ2Btv_P"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown\n",
        "response = rag_chain.invoke(\"tell about cats and its one bad habit and one good habit?\")\n",
        "\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roqc7eSStyBl",
        "outputId": "b40456e5-2c79-4088-a0a0-be293ba0f475"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on the provided text, we only know that cats are independent and enjoy their own space.  This could be considered a good habit (independence) and could also be interpreted as a potential bad habit (lack of interaction/dependence on owners, depending on the owner's perspective).  To provide a more complete answer, additional information is needed.  The provided text alone is insufficient to describe a definitively \"good\" and \"bad\" habit.\n"
          ]
        }
      ]
    }
  ]
}